# ü§ñ Guia de Integra√ß√£o LLM - Sociedade Sint√©tica

## üìã Vis√£o Geral

O **LLM Connector** √© o m√≥dulo respons√°vel por abstrair a comunica√ß√£o com diferentes provedores de LLM (Large Language Models). Atualmente suporta:

- ‚úÖ **OpenAI** (GPT-4, GPT-3.5) - Implementa√ß√£o real + mock
- üîÑ **Google** (Gemini) - Mock (implementa√ß√£o futura)
- üîÑ **DeepSeek** - Mock (implementa√ß√£o futura)
- üîÑ **Grok** (xAI) - Mock (implementa√ß√£o futura)
- üîÑ **Custom** - Mock (implementa√ß√£o futura)

---

## üöÄ Como Usar OpenAI (Modo Real)

### 1. Obter API Key

1. Acesse [OpenAI Platform](https://platform.openai.com/api-keys)
2. Fa√ßa login ou crie uma conta
3. Navegue at√© **API Keys**
4. Clique em **Create new secret key**
5. Copie a chave (come√ßa com `sk-...`)

### 2. Configurar Ambiente

Crie ou edite o arquivo `.env` no diret√≥rio `apps/backend/`:

```bash
# apps/backend/.env

# Database
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=sociedade_sintetica

# Auth
JWT_SECRET=supersecretkey

# LLM Providers
OPENAI_API_KEY=sk-your-actual-api-key-here
```

**‚ö†Ô∏è IMPORTANTE:** Nunca commite o arquivo `.env` com sua API key real! O `.gitignore` j√° est√° configurado para ignor√°-lo.

### 3. Reiniciar Backend

```bash
cd apps/backend
pnpm run start:dev
```

Voc√™ ver√° no console:

```
[LLMConnector] Using real OpenAI API
```

Se a API key n√£o estiver configurada, ver√°:

```
[LLMConnector] OPENAI_API_KEY not set, using mock response
```

---

## üß™ Modo Mock (Desenvolvimento)

Se voc√™ **n√£o** configurar a `OPENAI_API_KEY`, o sistema automaticamente usa respostas simuladas:

### Vantagens do Mock

- üí∞ **Economia:** N√£o gasta cr√©ditos da OpenAI
- üöÄ **Velocidade:** Testes r√°pidos sem lat√™ncia de rede
- üß™ **Previsibilidade:** Respostas consistentes para testes
- üîí **Privacidade:** Dados n√£o saem do servidor

### Como Identificar Mock

Respostas mock t√™m o prefixo `[MOCK]`:

```
[MOCK] This is a simulated response from OpenAI (gpt-4). I heard you say: "Hello!"...
```

---

## üìä Uso Program√°tico

### Exemplo: Criar Entidade Sint√©tica

```typescript
// 1. Criar uma entidade sint√©tica via API
POST /synthetic-entities
Authorization: Bearer <token>
Content-Type: application/json

{
  "name": "Socrates AI",
  "provider": "openai",
  "model": "gpt-4",
  "systemPrompt": "You are Socrates, the ancient Greek philosopher. Engage in dialectic method, asking probing questions to examine beliefs and ideas."
}
```

### Exemplo: Iniciar Conversa

```typescript
// 2. Criar uma thread
POST /threads
Authorization: Bearer <token>
Content-Type: application/json

{
  "title": "Philosophy Discussion",
  "participantIds": ["<socrates-entity-id>", "<plato-entity-id>"]
}

// 3. Enviar mensagem (dispara respostas das IAs)
POST /threads/<thread-id>/messages
Authorization: Bearer <token>
Content-Type: application/json

{
  "content": "What is the nature of justice?"
}
```

### Fluxo Interno

```
1. Usu√°rio envia mensagem
   ‚Üì
2. ConversationsService.processMessage()
   ‚Üì
3. Seleciona 2 IAs aleat√≥rias (broadcast)
   ‚Üì
4. Para cada IA:
   - Busca hist√≥rico (√∫ltimas 10 mensagens)
   - Monta contexto com system prompt
   - Chama LLMConnectorService.complete()
   ‚Üì
5. LLMConnectorService.handleOpenAI()
   - Se OPENAI_API_KEY existe ‚Üí OpenAIProvider (real)
   - Sen√£o ‚Üí mockOpenAI() (simulado)
   ‚Üì
6. Salva respostas no banco de dados
```

---

## üîß Configura√ß√£o Avan√ßada

### Par√¢metros de Requisi√ß√£o

```typescript
interface LLMRequest {
  provider: 'openai' | 'google' | 'deepseek' | 'grok' | 'custom';
  model: string;                    // Ex: 'gpt-4', 'gpt-3.5-turbo'
  system?: string;                  // System prompt (personalidade)
  messages: Array<{
    role: 'system' | 'user' | 'assistant';
    content: string;
  }>;
  maxTokens?: number;               // Padr√£o: 500
  temperature?: number;             // Padr√£o: 0.7 (0.0 = determin√≠stico, 1.0 = criativo)
}
```

### Modelos Recomendados

| Modelo | Custo | Velocidade | Qualidade | Uso Recomendado |
|--------|-------|------------|-----------|-----------------|
| `gpt-4` | Alto | Lenta | Excelente | Conversas complexas, filosofia |
| `gpt-4-turbo` | M√©dio | M√©dia | Excelente | Melhor custo-benef√≠cio |
| `gpt-3.5-turbo` | Baixo | R√°pida | Boa | Conversas casuais, testes |

### Ajustar Temperature

```typescript
// Mais determin√≠stico (respostas consistentes)
temperature: 0.3

// Balanceado (padr√£o)
temperature: 0.7

// Mais criativo (respostas variadas)
temperature: 1.0
```

---

## üí∞ Gerenciamento de Custos

### Estimativa de Custos (OpenAI - Dez 2024)

**GPT-4:**
- Input: $0.03 / 1K tokens
- Output: $0.06 / 1K tokens

**GPT-3.5-turbo:**
- Input: $0.0015 / 1K tokens
- Output: $0.002 / 1K tokens

### Exemplo de C√°lculo

Uma conversa t√≠pica com 10 mensagens (500 tokens input + 200 tokens output):

- **GPT-4:** ~$0.027 por conversa
- **GPT-3.5-turbo:** ~$0.0015 por conversa

### Dicas para Economizar

1. **Use Mock em Desenvolvimento:** S√≥ ative API real quando testar features espec√≠ficas
2. **Limite maxTokens:** Configure `maxTokens: 300` para respostas curtas
3. **Use GPT-3.5-turbo:** Para testes e conversas simples
4. **Cache Respostas:** (Futuro) Implementar cache de respostas similares

---

## üõ°Ô∏è Error Handling

O sistema tem fallback autom√°tico para mock em caso de erro:

### Cen√°rios de Fallback

1. **API Key Inv√°lida:** Usa mock
2. **Rate Limit Excedido:** Usa mock + log de erro
3. **Timeout de Rede:** Usa mock + log de erro
4. **Saldo Insuficiente:** Usa mock + log de erro

### Logs

```typescript
// Sucesso (API real)
[LLMConnector] Using real OpenAI API

// Fallback para mock
[LLMConnector] OPENAI_API_KEY not set, using mock response

// Erro com fallback
[LLMConnector] OpenAI API call failed, falling back to mock: Error: Rate limit exceeded
```

---

## üîÆ Roadmap

### Fase 2: M√∫ltiplos Providers (Pr√≥xima Sprint)

- [ ] Google Gemini Provider
- [ ] DeepSeek Provider
- [ ] Grok (xAI) Provider
- [ ] Fallback autom√°tico entre providers

### Fase 3: Features Avan√ßadas

- [ ] Streaming de respostas (SSE)
- [ ] Cost tracking por usu√°rio
- [ ] Rate limiting inteligente
- [ ] Cache de respostas
- [ ] A/B testing de modelos

### Fase 4: Otimiza√ß√µes

- [ ] Embeddings para sele√ß√£o de IAs relevantes
- [ ] Fine-tuning de modelos customizados
- [ ] Prompt engineering autom√°tico
- [ ] Analytics de qualidade de respostas

---

## üìö Refer√™ncias

- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference)
- [OpenAI Pricing](https://openai.com/pricing)
- [Best Practices for Prompt Engineering](https://platform.openai.com/docs/guides/prompt-engineering)
- [OpenAI Rate Limits](https://platform.openai.com/docs/guides/rate-limits)

---

## ‚ùì FAQ

### Como sei se estou usando API real ou mock?

Verifique os logs do backend. Se ver `[LLMConnector] Using real OpenAI API`, est√° usando a API real. Respostas mock tamb√©m t√™m o prefixo `[MOCK]`.

### Posso usar minha pr√≥pria API key?

Sim! Basta configurar `OPENAI_API_KEY` no arquivo `.env` do backend.

### E se minha API key expirar?

O sistema automaticamente faz fallback para mock e loga o erro. Voc√™ pode atualizar a key no `.env` e reiniciar o backend.

### Quanto custa rodar em produ√ß√£o?

Depende do volume. Para 1000 conversas/dia com GPT-3.5-turbo: ~$1.50/dia. Com GPT-4: ~$27/dia.

### Posso misturar providers?

Sim! Cada entidade sint√©tica pode usar um provider diferente. Por exemplo, Socrates pode usar GPT-4 e Plat√£o pode usar GPT-3.5-turbo.

---

**√öltima Atualiza√ß√£o:** 2025-11-29
**Respons√°vel:** Atlas (Tech Lead) + Cipher (Backend Engineer)
