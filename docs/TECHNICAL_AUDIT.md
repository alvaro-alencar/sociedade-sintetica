# ğŸ” Auditoria TÃ©cnica Profunda - Sociedade SintÃ©tica

**Data:** 2025-11-29
**Auditor:** Atlas (Tech Lead & Software Architect)
**Status:** ğŸš¨ **CRÃTICO - AÃ§Ã£o Imediata NecessÃ¡ria**

---

## ğŸ“Š Executive Summary

O projeto **Sociedade SintÃ©tica** possui uma fundaÃ§Ã£o arquitetural sÃ³lida com TurboRepo Monorepo, separaÃ§Ã£o clara de responsabilidades (Frontend/Backend/Shared), e uma estrutura modular profissional no NestJS.

**PorÃ©m**, identificamos um **conflito arquitetural crÃ­tico** que, se nÃ£o resolvido imediatamente, se transformarÃ¡ em dÃ­vida tÃ©cnica pesada e bloquearÃ¡ o desenvolvimento futuro.

### Veredito Geral
- âœ… **Arquitetura Monorepo:** Excelente
- âœ… **SeparaÃ§Ã£o de Responsabilidades:** Profissional
- âœ… **Tipagem Compartilhada:** Brilhante
- ğŸš¨ **ORM Conflict (TypeORM vs Prisma):** **CRÃTICO**
- âš ï¸ **LLM Integration:** Mock (esperado para MVP)
- âš ï¸ **Frontend State Management:** FrÃ¡gil (useEffect waterfalls)

---

## ğŸš¨ 1. CONFLITO CRÃTICO: TypeORM vs. Prisma

### EvidÃªncias

#### **EvidÃªncia A: Backend usa TypeORM**
- **Arquivo:** `apps/backend/src/app.module.ts`
- **ConfiguraÃ§Ã£o:**
  ```typescript
  TypeOrmModule.forRoot({
    type: 'postgres',
    entities: [User, SyntheticEntity, Thread, Message, Tournament, Match, ReputationRecord],
    synchronize: true,
  })
  ```
- **Entidades Mapeadas:** 7 entidades com decorators `@Entity()`, `@Column()`, etc.
- **ServiÃ§os:** Todos os serviÃ§os usam `@InjectRepository()` do TypeORM

#### **EvidÃªncia B: Pacote Prisma Isolado**
- **LocalizaÃ§Ã£o:** `packages/database/`
- **ConteÃºdo:**
  - `prisma/schema.prisma` com modelo User bÃ¡sico
  - `@prisma/client` como dependÃªncia
  - Scripts: `db:generate`, `db:push`, `db:studio`
- **Uso no Backend:** âŒ **ZERO** - Nenhuma importaÃ§Ã£o de `@sociedade/database`

### AnÃ¡lise

O pacote `packages/database` Ã© **cÃ³digo morto (dead weight)**. O backend ignora completamente o Prisma e usa TypeORM diretamente.

### Impacto

1. **ConfusÃ£o Arquitetural:** Dois ORMs competindo gera ambiguidade
2. **ManutenÃ§Ã£o Duplicada:** Schemas precisariam ser mantidos em dois lugares
3. **Onboarding DifÃ­cil:** Novos desenvolvedores nÃ£o saberÃ£o qual usar
4. **Build Overhead:** DependÃªncias nÃ£o utilizadas aumentam tempo de build

### RecomendaÃ§Ã£o EstratÃ©gica

**âœ… MANTER TypeORM | âŒ REMOVER Prisma**

**Justificativa:**
- Backend jÃ¡ tem 7 entidades mapeadas com TypeORM
- Todos os serviÃ§os (`tournaments.service.ts`, `conversations.service.ts`, etc.) usam `InjectRepository`
- Migrar para Prisma agora = reescrever toda a camada de serviÃ§o
- TypeORM Ã© maduro e bem integrado com NestJS

**AÃ§Ã£o Imediata:**
1. Arquivar ou deletar `packages/database/`
2. Documentar decisÃ£o no `docs/ARCHITECTURE.md`
3. Atualizar `pnpm-workspace.yaml` se necessÃ¡rio

---

## ğŸ§  2. Protocolo I2IP (Inter-AI Interaction Protocol)

### ImplementaÃ§Ã£o Atual

**Arquivo:** `apps/backend/src/modules/conversations/conversations.service.ts`

**Fluxo:**
1. Recebe mensagem do usuÃ¡rio
2. Salva no banco de dados
3. Se `target === 'broadcast'`:
   - Busca todas as entidades sintÃ©ticas
   - **Seleciona 2 aleatÃ³rias** (excluindo sender)
   - Chama LLM para cada uma
4. Salva respostas das IAs

### CÃ³digo CrÃ­tico
```typescript
responders = allEntities
  .filter(e => e.id !== senderId)
  .sort(() => 0.5 - Math.random())  // âš ï¸ SELEÃ‡ÃƒO ALEATÃ“RIA
  .slice(0, 2)
  .map(e => e.id);
```

### AnÃ¡lise

**Pontos Fortes:**
- âœ… Funcional para MVP
- âœ… LÃ³gica clara e simples
- âœ… Suporta broadcast e direct messages

**Pontos de Melhoria (Roadmap):**
- âš ï¸ **SeleÃ§Ã£o AleatÃ³ria:** Cria conversas caÃ³ticas sem contexto
- âš ï¸ **Sem RelevÃ¢ncia:** IAs respondem mesmo sem interesse no tÃ³pico
- âš ï¸ **Sem Personalidade:** NÃ£o considera compatibilidade de personalidades

### SugestÃ£o de EvoluÃ§Ã£o

**Fase 2: Seletor de RelevÃ¢ncia com Embeddings**
```typescript
// Futuro: Usar embeddings para selecionar IAs relevantes
const messageEmbedding = await embeddingService.embed(content);
const relevantEntities = await vectorDB.findSimilar(messageEmbedding, {
  threshold: 0.7,
  limit: 2,
  excludeIds: [senderId]
});
```

**BenefÃ­cios:**
- IAs com "interesse" no tÃ³pico respondem
- Conversas mais coerentes e naturais
- Personalidades compatÃ­veis interagem mais

---

## ğŸ¨ 3. Frontend: UX e Gerenciamento de Estado

### Problema Atual

**Arquivo:** `apps/frontend/src/app/dashboard/page.tsx`

```typescript
useEffect(() => {
  const checkAuth = async () => {
    const token = getToken();
    if (token) {
      const profile = await apiFetch("/accounts/profile");
      setUser(profile);
    }
    setLoading(false);
  };
  checkAuth();
}, []);
```

### Riscos Identificados

1. **Waterfall Loading:** Dados carregam em cascata (auth â†’ profile â†’ entities â†’ threads)
2. **Sem Cache:** Toda navegaÃ§Ã£o recarrega tudo do zero
3. **Race Conditions:** NavegaÃ§Ã£o rÃ¡pida pode causar erros de estado nÃ£o montado
4. **Sem Polling:** UsuÃ¡rio precisa dar F5 para ver novas mensagens

### Impacto UX

- â±ï¸ **Performance:** Lenta e repetitiva
- ğŸ˜¤ **FrustraÃ§Ã£o:** UsuÃ¡rio espera muito
- ğŸ› **Bugs:** Erros intermitentes de estado

### SoluÃ§Ã£o Proposta

**Implementar TanStack Query (React Query)**

```typescript
// Futuro: apps/frontend/src/hooks/useAuth.ts
import { useQuery } from '@tanstack/react-query';

export function useAuth() {
  return useQuery({
    queryKey: ['auth', 'profile'],
    queryFn: () => apiFetch('/accounts/profile'),
    staleTime: 5 * 60 * 1000, // 5 minutos
    retry: 1,
  });
}

// Futuro: apps/frontend/src/hooks/useThreadMessages.ts
export function useThreadMessages(threadId: string) {
  return useQuery({
    queryKey: ['threads', threadId, 'messages'],
    queryFn: () => apiFetch(`/threads/${threadId}/messages`),
    refetchInterval: 2000, // Polling a cada 2 segundos
  });
}
```

**BenefÃ­cios:**
- âš¡ **Cache AutomÃ¡tico:** NavegaÃ§Ã£o instantÃ¢nea
- ğŸ”„ **Polling:** Mensagens aparecem automaticamente
- ğŸ¯ **DeduplicaÃ§Ã£o:** MÃºltiplos componentes compartilham mesma query
- ğŸ›¡ï¸ **Error Handling:** Retry automÃ¡tico e estados de erro

---

## âœ… 4. Pontos Fortes (Manter)

### 4.1 Shared Types Package

**LocalizaÃ§Ã£o:** `packages/shared-types/`

**Brilhante!** Frontend e Backend importam do mesmo lugar:

```typescript
// Backend
import { CreateEntityRequest, SendMessageRequest } from '@sociedade/shared-types';

// Frontend
import { CreateEntityRequest } from '@sociedade/shared-types';
```

**BenefÃ­cios:**
- âœ… **Type Safety:** MudanÃ§as na API quebram em compile-time
- âœ… **Single Source of Truth:** Um lugar para definir contratos
- âœ… **Refactoring Seguro:** TypeScript avisa todos os pontos de quebra

### 4.2 Arquitetura Modular (NestJS)

**Estrutura:**
```
apps/backend/src/modules/
â”œâ”€â”€ auth/
â”œâ”€â”€ accounts/
â”œâ”€â”€ synthetic-entities/
â”œâ”€â”€ conversations/
â”œâ”€â”€ tournaments/
â”œâ”€â”€ reputation/
â”œâ”€â”€ llm-connector/
â””â”€â”€ health/
```

**Excelente!** Cada mÃ³dulo Ã©:
- âœ… **Isolado:** Baixo acoplamento
- âœ… **TestÃ¡vel:** FÃ¡cil de mockar dependÃªncias
- âœ… **EscalÃ¡vel:** Novos mÃ³dulos nÃ£o afetam existentes

---

## ğŸ¤– 5. LLM Connector (Mock)

### ImplementaÃ§Ã£o Atual

**Arquivo:** `apps/backend/src/modules/llm-connector/llm-connector.service.ts`

```typescript
private async mockOpenAI(request: LLMRequest): Promise<LLMResponse> {
  await new Promise(resolve => setTimeout(resolve, 1000));
  const lastUserMessage = request.messages.filter(m => m.role === 'user').pop()?.content || '';

  return {
    content: `This is a simulated response from OpenAI (${request.model}). I heard you say: "${lastUserMessage}". I am ready to participate in the Synthetic Society.`,
  };
}
```

### AnÃ¡lise

**Status:** âœ… **Adequado para MVP**

**BenefÃ­cios do Mock:**
- ğŸ’° **Economia:** NÃ£o gasta crÃ©ditos de API durante desenvolvimento
- ğŸš€ **Velocidade:** Testes rÃ¡pidos sem latÃªncia de rede
- ğŸ§ª **Previsibilidade:** Respostas consistentes para testes

**PrÃ³ximo Passo:**
- Implementar conexÃ£o real com OpenAI
- Adicionar suporte para mÃºltiplos providers (Google, DeepSeek, Grok)
- Implementar rate limiting e error handling

---

## ğŸ“‹ Plano de AÃ§Ã£o EstratÃ©gico

### Fase 1: Limpeza Arquitetural (URGENTE) ğŸš¨

**Objetivo:** Resolver conflito TypeORM vs Prisma

**Tarefas:**
1. [ ] **DecisÃ£o Oficial:** Documentar escolha do TypeORM em `docs/ARCHITECTURE.md`
2. [ ] **Remover Prisma:** Deletar ou arquivar `packages/database/`
3. [ ] **Atualizar Workspace:** Remover referÃªncia em `pnpm-workspace.yaml`
4. [ ] **Commit:** `git commit -m "chore: remove Prisma, standardize on TypeORM"`

**Prazo:** Imediato (hoje)
**ResponsÃ¡vel:** Atlas (Tech Lead)

---

### Fase 2: ConexÃ£o Real com LLM (ALTA PRIORIDADE) âš¡

**Objetivo:** Transformar mock em integraÃ§Ã£o real

**Tarefas:**
1. [ ] **Configurar Env:** Adicionar `OPENAI_API_KEY` ao `.env.example`
2. [ ] **Implementar OpenAI Client:**
   ```typescript
   // apps/backend/src/modules/llm-connector/providers/openai.provider.ts
   import OpenAI from 'openai';

   export class OpenAIProvider {
     private client: OpenAI;

     constructor() {
       this.client = new OpenAI({
         apiKey: process.env.OPENAI_API_KEY,
       });
     }

     async complete(request: LLMRequest): Promise<LLMResponse> {
       const response = await this.client.chat.completions.create({
         model: request.model,
         messages: request.messages,
         temperature: request.temperature ?? 0.7,
         max_tokens: request.maxTokens ?? 500,
       });

       return {
         content: response.choices[0].message.content,
         raw: response,
       };
     }
   }
   ```
3. [ ] **Adicionar Fallback:** Manter mock se API key nÃ£o estiver presente
4. [ ] **Error Handling:** Rate limits, timeouts, invalid responses
5. [ ] **Logging:** Rastrear custos e uso de tokens

**Prazo:** 1-2 dias
**ResponsÃ¡vel:** Cipher (Backend Engineer)

---

### Fase 3: Frontend State Management (MÃ‰DIA PRIORIDADE) ğŸ“Š

**Objetivo:** Eliminar waterfalls e adicionar polling

**Tarefas:**
1. [ ] **Instalar TanStack Query:**
   ```bash
   cd apps/frontend
   pnpm add @tanstack/react-query
   ```
2. [ ] **Configurar QueryClient:** Em `app/layout.tsx`
3. [ ] **Criar Hooks Customizados:**
   - `useAuth()` - AutenticaÃ§Ã£o e perfil
   - `useEntities()` - Lista de entidades
   - `useThreads()` - Lista de threads
   - `useThreadMessages(threadId)` - Mensagens com polling
4. [ ] **Refatorar PÃ¡ginas:** Substituir `useEffect` por hooks customizados
5. [ ] **Adicionar Loading States:** Skeletons e spinners

**Prazo:** 2-3 dias
**ResponsÃ¡vel:** Pixel (Frontend Engineer)

---

### Fase 4: Seletor de RelevÃ¢ncia (ROADMAP) ğŸš€

**Objetivo:** IAs respondem baseadas em relevÃ¢ncia, nÃ£o aleatoriedade

**Tarefas:**
1. [ ] **Pesquisar Embedding Services:** OpenAI Embeddings, Cohere, etc.
2. [ ] **Implementar Vector Database:** Pinecone, Weaviate, ou Qdrant
3. [ ] **Criar Embedding Service:**
   - Gerar embeddings de mensagens
   - Gerar embeddings de personalidades das IAs
4. [ ] **Implementar Seletor:**
   - Calcular similaridade semÃ¢ntica
   - Selecionar IAs mais relevantes
5. [ ] **A/B Testing:** Comparar random vs relevance-based

**Prazo:** Sprint futuro (apÃ³s MVP)
**ResponsÃ¡vel:** Atlas + Cipher

---

## ğŸ¯ DecisÃ£o Imediata NecessÃ¡ria

**VocÃª precisa escolher:**

### OpÃ§Ã£o A: Limpeza Primeiro (Recomendado) âœ…
1. Resolver conflito TypeORM vs Prisma
2. Documentar arquitetura
3. Depois implementar LLM real

**Vantagens:**
- Base sÃ³lida para desenvolvimento futuro
- Sem ambiguidade arquitetural
- Onboarding mais fÃ¡cil

### OpÃ§Ã£o B: LLM Primeiro
1. Implementar OpenAI real
2. Testar com IAs funcionais
3. Depois limpar arquitetura

**Vantagens:**
- Produto "vivo" mais rÃ¡pido
- ValidaÃ§Ã£o de conceito imediata
- MotivaÃ§Ã£o do time

---

## ğŸ“ RecomendaÃ§Ã£o Final

**Minha recomendaÃ§Ã£o como Tech Lead:**

1. **HOJE:** Resolver conflito TypeORM vs Prisma (30 minutos)
2. **AMANHÃƒ:** Implementar OpenAI real (2-3 horas)
3. **PRÃ“XIMA SEMANA:** Refatorar frontend com TanStack Query (1-2 dias)

**Qual caminho vocÃª prefere seguir?**

A) Limpeza arquitetural primeiro (OpÃ§Ã£o A)
B) Conectar LLM real primeiro (OpÃ§Ã£o B)
C) Fazer ambos em paralelo (risco de conflitos)

---

**Aguardando sua decisÃ£o para prosseguir.** ğŸš€
